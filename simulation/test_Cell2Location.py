# -*- coding: utf-8 -*-
"""cell2location_script.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YuU_kAFL9p1Npe2LdwVC0y4Bpff2xVuK
"""

"""####loading adata from counts csv"""

import logging

# Configure global logging format
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
    force=True
)

LOGGER = logging.getLogger('Starfysh')

def preprocess(adata_raw,
               lognorm=True,
               min_perc=None,
               max_perc=None,
               n_top_genes=6000,
               mt_thld=100,
               verbose=True,
               multiple_data=False
               ):
    """
    Preprocessing ST gexp matrix, remove Ribosomal & Mitochondrial genes
    Parameters
    ----------
    adata_raw : annData
        Spot x Bene raw expression matrix [S x G]
    min_perc : float
        lower-bound percentile of non-zero gexps for filtering spots
    max_perc : float
        upper-bound percentile of non-zero gexps for filtering spots
    n_top_genes: float
        number of the variable genes
    mt_thld : float
        max. percentage of mitochondrial gexps for filtering spots
        with excessive MT expressions
    multiple_data: bool
        whether the study need integrate datasets
    """
    adata = adata_raw.copy()

    if min_perc and max_perc:
        assert 0 < min_perc < max_perc < 100, \
            "Invalid thresholds for cells: {0}, {1}".format(min_perc, max_perc)
        min_counts = np.percentile(adata.obs['total_counts'], min_perc)
        sc.pp.filter_cells(adata, min_counts=min_counts)

    # Remove cells with excessive MT expressions
    # Remove MT & RB genes

    if verbose:
        LOGGER.info('Preprocessing1: delete the mt and rp')
    adata.var['mt'] = adata.var_names.str.startswith('MT-')
    adata.var['rb'] = np.logical_or(
        adata.var_names.str.startswith('RPS'),
        adata.var_names.str.startswith('RPL')
    )

    sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], inplace=True)
    mask_cell = adata.obs['pct_counts_mt'] < mt_thld
    mask_gene = np.logical_and(~adata.var['mt'], ~adata.var['rb'])

    adata = adata[mask_cell, mask_gene]
    sc.pp.filter_genes(adata, min_cells=1)

    if lognorm:
        if verbose:
            LOGGER.info('Preprocessing2: Normalize')
        if multiple_data:
            sc.pp.normalize_total(adata, target_sum=1e6, inplace=True)
        else:
            sc.pp.normalize_total(adata, inplace=True)

        # Preprocessing3: Logarithm
        if verbose:
            LOGGER.info('Preprocessing3: Logarithm')
        sc.pp.log1p(adata)
    else:
        if verbose:
            LOGGER.info('Skip Normalize and Logarithm')

    # Preprocessing4: Find the variable genes
    if verbose:
        LOGGER.info('Preprocessing4: Find the variable genes')
    sc.pp.highly_variable_genes(adata, flavor='seurat', n_top_genes=n_top_genes, inplace=True)

    return adata

def load_adata(data_folder, sample_id, n_genes, multiple_data=False):
    """
    load visium adata with raw counts, preprocess & extract highly variable genes
    Parameters
    ----------
        data_folder : str
            Root directory of the data
        sample_id : str
            Sample subdirectory under `data_folder`
        n_genes : int
            the number of the gene for training
        multiple_data: bool
            whether the study include multiple datasets
    Returns
    -------
        adata : sc.AnnData
            Processed ST raw counts
        adata_norm : sc.AnnData
            Processed ST normalized & log-transformed data
    """
    has_feature_h5 = os.path.isfile(
        os.path.join(data_folder, sample_id, 'filtered_feature_bc_matrix.h5')
    ) # whether dataset stored in h5 with spatial info.

    if has_feature_h5:
        adata = sc.read_visium(path=os.path.join(data_folder, sample_id), library_id=sample_id)
        adata.var_names_make_unique()
        adata.obs['sample'] = sample_id
    elif sample_id.startswith('simu'): # simulations
        adata = sc.read_csv(os.path.join(data_folder, sample_id, 'counts.st_synth.csv'))
    else:
        filenames = [
            f[:-5] for f in os.listdir(os.path.join(data_folder, sample_id))
            if f[-5:] == '.h5ad'
        ]
        assert len(filenames) == 1, \
            "None or more than `h5ad` file in the data directory," \
            "please contain only 1 target ST file in the given directory"
        adata = sc.read_h5ad(os.path.join(data_folder, sample_id, filenames[0] + '.h5ad'))
        adata.var_names_make_unique()
        adata.obs['sample'] = sample_id

    if '_index' in adata.var.columns:
        adata.var_names = adata.var['_index']
        adata.var_names.name = 'Genes'
        adata.var.drop('_index', axis=1, inplace=True)

    adata_norm = preprocess(adata, n_top_genes=n_genes,multiple_data=multiple_data)
    adata = adata[:, list(adata_norm.var_names)]
    adata.var['highly_variable'] = adata_norm.var['highly_variable']
    adata.obs = adata_norm.obs

    return adata, adata_norm

"""#### benchmarking"""

import scanpy as sc
import numpy as np
import matplotlib.pyplot as plt
import matplotlib as mpl

import cell2location

from matplotlib import rcParams
rcParams['pdf.fonttype'] = 42 # enables correct plotting of text for PDFs

import pandas as pd
import os
from scipy.io import mmread

spatial_path = './'
sc_path = './scrna'

results_folder = './cell2location_results'

# create paths and names to results folders for reference regression and cell2location models
ref_run_name = f'{results_folder}/reference_signatures'
run_name = f'{results_folder}/cell2location_map'

# Load cell & gene labels
barcode_df = pd.read_csv(
    os.path.join(sc_path, 'count_matrix_barcodes.tsv'), 
    delimiter='\t',
    header=None # this file doesn't contain the true "header" (column info), the first row is a TRUE barcode
)

gene_df = pd.read_csv(
    os.path.join(sc_path, 'count_matrix_genes.tsv'),
    delimiter='\t',
    header=None # this file doesn't contain the true "header" (column info), the first row is a TRUE gene
)

print('# cells: {0}, # genes: {1}'.format(len(barcode_df), len(gene_df)))

# Construct adata object for scRNA-seq
barcodes = pd.DataFrame(barcode_df[0].values, index=barcode_df[0].values, columns=['Barcode'])
genes = pd.DataFrame(gene_df[0].values, index=gene_df[0].values, columns=['features'])

cnt = mmread(
    os.path.join(sc_path, 'count_matrix_sparse.mtx')
).toarray()

adata_sc = sc.AnnData(
    X=cnt.T,
    obs=barcodes,
    var=genes
)

print(adata_sc.shape)

meta_df = pd.read_csv(
    os.path.join(sc_path, 'metadata.csv'), index_col=[0], header=[0]
)
print(meta_df.head())

adata_sc.obs['major_cell_types'] = meta_df['celltype_major']
adata_sc.obs['minor_cell_types'] = meta_df['celltype_minor']
adata_sc.obs['subset_cell_types'] = meta_df['celltype_subset']
print(adata_sc.obs)

annot_lbl = 'celltype_subset'
print(meta_df[annot_lbl].value_counts())

adata_st, adata_st_normed = load_adata(data_folder=spatial_path,  # root data directory
                                       sample_id='simu_defined',  # sample_id
                                       n_genes=2000  # number of highly variable genes to keep
                                      )

print(adata_st.shape)

sc.pl.highest_expr_genes(adata_sc, n_top=20)
print(adata_sc)

from cell2location.utils.filtering import filter_genes
selected = filter_genes(adata_sc, cell_count_cutoff=5, cell_percentage_cutoff2=0.03, nonz_mean_cutoff=1.12)

adata_sc = adata_sc[:, selected].copy()
print(adata_sc)

cell2location.models.RegressionModel.setup_anndata(adata=adata_sc, labels_key='subset_cell_types')

# estimating reference cell type signatures

from cell2location.models import RegressionModel
mod = RegressionModel(adata_sc)

mod.view_anndata_setup()

mod.train(max_epochs=350, use_gpu=False)

mod.plot_history(20)

adata_sc = mod.export_posterior(adata_sc, sample_kwargs={'num_samples': 1000,
                                                         'batch_size': 2500,
                                                         'use_gpu': False})

mod.save(f"{ref_run_name}", overwrite=True)
adata_file = f"{ref_run_name}/sc.h5ad"
adata_sc.write(adata_file)
# adata_file

mod.plot_QC()

if 'means_per_cluster_mu_fg' in adata_sc.varm.keys():
    inf_aver = adata_sc.varm['means_per_cluster_mu_fg'][[f'means_per_cluster_mu_fg_{i}'
                                    for i in adata_sc.uns['mod']['factor_names']]].copy()
else:
    inf_aver = adata_sc.var[[f'means_per_cluster_mu_fg_{i}'
                                    for i in adata_sc.uns['mod']['factor_names']]].copy()
inf_aver.columns = adata_sc.uns['mod']['factor_names']
print(inf_aver.iloc[0:5, 0:5])

# spatial mapping

intersect = np.intersect1d(adata_st.var_names, inf_aver.index)
adata_st = adata_st[:, intersect].copy()
inf_aver = inf_aver.loc[intersect, :].copy()

cell2location.models.Cell2location.setup_anndata(adata=adata_st)

mod_st = cell2location.models.Cell2location(adata_st, cell_state_df=inf_aver, N_cells_per_location=30, detection_alpha=20)
mod_st.view_anndata_setup()

mod_st.train(max_epochs=10000, batch_size=None, train_size=1, use_gpu=False)

mod_st.plot_history(1000)
plt.legend(labels=['full data training'])

adata_st = mod_st.export_posterior(
    adata_st, sample_kwargs={'num_samples': 1000, 'batch_size': mod.adata.n_obs,
                             'use_gpu': False}
)

if '_index' in adata_st.var.columns:
  adata_st.var_names = adata_st.var['_index']

mod_st.save(f"{run_name}", overwrite=True)
adata_file = f"{run_name}/sp.h5ad"
adata_st.write(adata_file)
# adata_file

mod_st.plot_QC()
